{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose\n",
    "in this notebook we use a pretrained neural network to extract features for every image downloaded in notebook 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append('../Src')\n",
    "from nn_extractor import NNExtractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reload out GRID object, defined in notebook 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from img_lib import RasterGrid\n",
    "GRID = RasterGrid(\"../tmp/local_raster.tif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### loading the pre-trained model\n",
    "now we load the NNExtractor. This object handles the neural network (type is defined the config) used to extract the features. For more informartion on how the networks are trained, please visit [this](https://github.com/WFP-VAM/HRM_NN_Training) repository. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: loading JB's crappy model for Google Images ...\n"
     ]
    }
   ],
   "source": [
    "network = NNExtractor(4004, # config_id\n",
    "                      'Google', # Satellite, either Google or Sentinel\n",
    "                      '../Data/Satellite/Google', # images directory\n",
    "                      'Google', # model for the Google images\n",
    "                      0, # buffer step\n",
    "                      GRID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract features\n",
    "Now each image in the `output_image_dir` is scored by the model and the features are returned. PCA will reduce the number of features from 256 to 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('../Data/datasets/VAM_ENSAN_Mali_2018_cluster.csv')\n",
    "list_i, list_j = GRID.get_gridcoordinates(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature extraction : 970 tiles out of 979\r"
     ]
    }
   ],
   "source": [
    "features = network.extract_features(list_i, list_j, \n",
    "                                    'Google', # Satellite, either Google or Sentinel \n",
    "                                     '2018-01-01', # images dates start\n",
    "                                     '2018-08-01' # images dates end\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features.to_csv('../Data/Features/Google_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
